---
title: Home
layout: page
# Index page
---

<h2>About me</h2>
Hello! I am Ankit Pratap Singh. I am a PhD candidate in the <a href="https://www.ece.iastate.edu/" target="_blank">Department of Electrical and Computer Engineering</a> at <a href="https://www.iastate.edu/" target="_blank">Iowa State University</a>, advised by Professor <a href="https://www.ece.iastate.edu/~namrata/" target="_blank">Namrata Vaswani</a>. I am currently working as an <b>AI Researcher at Thoughtworks</b>, focusing on developing intelligent and scalable data generation systems. My <b>research interests</b> include <b>Optimization</b>, <b>Agentic AI</b>, <b>Reinforcement Learning</b>, <b>Multi-Task Representation Learning</b>, and <b>Secure Federated Learning</b>. During my <a href="https://singhankitpratap.github.io/research/" target="_blank">Ph.D.</a>, I worked on <b>Secure Federated Learning</b>, <b>Reinforcement Learning</b>, and <b>Multi-Task Representation Learning</b>, leading to publications in <b>ICML</b> and <b>IEEE Transactions on Information Theory (T-IT)</b>. At the <a href="https://singhankitpratap.github.io/industry/" target="_blank">IFC (World Bank Group)</a>, I developed a <b>multi-agent LLM system</b> for the <b>Financial Spreading</b> problem, integrating document understanding and reasoning for large-scale financial analysis. I am continually seeking and open to <b>collaborations</b> on impactful projects at the intersection of AI, optimization, and distributed learning. 

<a href="https://singhankitpratap.github.io/sap_files/transformer_m.pdf" target="_blank">A Mathematical Perspective on Transformers</a>: Sometimes, a mathematical framework makes it easier to understand concepts than relying on abstract explanations.

<h2>Recent News</h2>
<ul>
    <li>Joined <a href="https://www.thoughtworks.com/en-us" target="_blank">Thoughtworks</a> as <b>AI Researcher</b></li>
    <li>Joined <a href="https://www.ifc.org/en/home" target="_blank">International Finance Corporation (World Bank)</a> as <b>ML Researcher</b></li>
    <li>Paper on Byzantine-Resilient Federated Alternating Gradient Descent and Minimization for Partly-Decoupled Low Rank Matrix Learning is accepted in <b>ICML 2025</b></li>
    <li>Paper on Secure Algorithms for Vertically Federated Multi-Task Representation Learning is accepted in <b>ISIT 2025</b></li>
    <li>Paper on Byzantine-resilient federated pca and low rank column-wise sensing is accepted in <b>IEEE Transactions on Information Theory Journal</b></li>
    <li>Paper on Byzantine Resilient and Fast Federated Few-Shot Learning is accepted in <b>ICML 2024</b></li>
    <li>Paper on Byzantine-Resilient Federated Principal Subspace Estimation is accepted in <b>ISIT 2024</b></li>
</ul>

<h3>Research Interests</h3>
<ul>
    <li>Agentic AI</li>
    <li>Robust Machine Learning</li>
    <li>Federated learning</li>
    <li>Information Theory</li>
</ul>


